{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Risk Management and Monitoring\n",
    "\n",
    "This notebook covers:\n",
    "- Real-time risk monitoring systems\n",
    "- Dynamic hedging strategies\n",
    "- Regime detection and adaptation\n",
    "- Risk attribution analysis\n",
    "- Early warning systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Risk management libraries\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Custom modules\n",
    "from src.data.loader import DataLoader\n",
    "from src.risk.manager import RiskManager\n",
    "from src.utils.logger import setup_logger\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = setup_logger(__name__)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Risk management libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Portfolio Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load market data\n",
    "loader = DataLoader()\n",
    "data = loader.load_data(['TSLA', 'BND', 'SPY'], '2015-07-01', '2025-07-31')\n",
    "prices = data['prices']\n",
    "returns = data['returns']\n",
    "\n",
    "# Load portfolio recommendation\n",
    "try:\n",
    "    with open('../data/portfolio_recommendation.pkl', 'rb') as f:\n",
    "        portfolio_rec = pickle.load(f)\n",
    "    recommended_weights = portfolio_rec['weights']\n",
    "    print(\"‚úì Portfolio recommendation loaded\")\nexcept FileNotFoundError:\n",
    "    print(\"‚úó Using default weights\")\n",
    "    recommended_weights = {'TSLA': 0.4, 'BND': 0.3, 'SPY': 0.3}\n",
    "\n",
    "# Calculate portfolio returns\n",
    "weights_series = pd.Series(recommended_weights)\n",
    "portfolio_returns = (returns * weights_series).sum(axis=1)\n",
    "\n",
    "print(f\"Portfolio weights: {recommended_weights}\")\n",
    "print(f\"Analysis period: {returns.index.min()} to {returns.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Detection and Market State Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketRegimeDetector:\n",
    "    \"\"\"\n",
    "    Detect market regimes using various statistical methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns_data, window=60):\n",
    "        self.returns = returns_data\n",
    "        self.window = window\n",
    "        \n",
    "    def calculate_regime_features(self):\n",
    "        \"\"\"\n",
    "        Calculate features for regime detection\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=self.returns.index)\n",
    "        \n",
    "        # Rolling statistics\n",
    "        features['volatility'] = self.returns.rolling(self.window).std() * np.sqrt(252)\n",
    "        features['mean_return'] = self.returns.rolling(self.window).mean() * 252\n",
    "        features['skewness'] = self.returns.rolling(self.window).skew()\n",
    "        features['kurtosis'] = self.returns.rolling(self.window).kurt()\n",
    "        \n",
    "        # VaR and CVaR\n",
    "        features['var_95'] = self.returns.rolling(self.window).quantile(0.05)\n",
    "        features['cvar_95'] = self.returns.rolling(self.window).apply(\n",
    "            lambda x: x[x <= x.quantile(0.05)].mean()\n",
    "        )\n",
    "        \n",
    "        # Trend indicators\n",
    "        price_proxy = (1 + self.returns).cumprod()\n",
    "        features['trend_strength'] = (\n",
    "            price_proxy / price_proxy.rolling(self.window).mean() - 1\n",
    "        )\n",
    "        \n",
    "        # Correlation with market (using SPY as proxy)\n",
    "        if 'SPY' in self.returns.columns:\n",
    "            spy_returns = self.returns['SPY']\n",
    "            features['market_correlation'] = self.returns.rolling(self.window).corr(spy_returns)\n",
    "        \n",
    "        return features.dropna()\n",
    "    \n",
    "    def detect_regimes_kmeans(self, n_regimes=3):\n",
    "        \"\"\"\n",
    "        Detect regimes using K-means clustering\n",
    "        \"\"\"\n",
    "        features = self.calculate_regime_features()\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=n_regimes, random_state=42, n_init=10)\n",
    "        regimes = kmeans.fit_predict(features_scaled)\n",
    "        \n",
    "        # Create regime series\n",
    "        regime_series = pd.Series(regimes, index=features.index)\n",
    "        \n",
    "        return regime_series, features, kmeans\n",
    "    \n",
    "    def analyze_regime_characteristics(self, regime_series, features):\n",
    "        \"\"\"\n",
    "        Analyze characteristics of each regime\n",
    "        \"\"\"\n",
    "        regime_stats = {}\n",
    "        \n",
    "        for regime in regime_series.unique():\n",
    "            regime_mask = regime_series == regime\n",
    "            regime_features = features[regime_mask]\n",
    "            regime_returns = self.returns[regime_mask]\n",
    "            \n",
    "            stats_dict = {\n",
    "                'frequency': regime_mask.sum(),\n",
    "                'percentage': regime_mask.mean() * 100,\n",
    "                'avg_volatility': regime_features['volatility'].mean(),\n",
    "                'avg_return': regime_features['mean_return'].mean(),\n",
    "                'avg_skewness': regime_features['skewness'].mean(),\n",
    "                'avg_kurtosis': regime_features['kurtosis'].mean(),\n",
    "                'avg_var': regime_features['var_95'].mean(),\n",
    "                'worst_drawdown': self._calculate_max_drawdown(regime_returns)\n",
    "            }\n",
    "            \n",
    "            regime_stats[f'Regime_{regime}'] = stats_dict\n",
    "        \n",
    "        return pd.DataFrame(regime_stats).T\n",
    "    \n",
    "    def _calculate_max_drawdown(self, returns_series):\n",
    "        \"\"\"\n",
    "        Calculate maximum drawdown for a returns series\n",
    "        \"\"\"\n",
    "        if len(returns_series) == 0:\n",
    "            return 0\n",
    "        \n",
    "        cumulative = (1 + returns_series).cumprod()\n",
    "        rolling_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - rolling_max) / rolling_max\n",
    "        return drawdown.min()\n",
    "\n",
    "# Initialize regime detector\n",
    "regime_detector = MarketRegimeDetector(portfolio_returns)\n",
    "\n",
    "# Detect regimes\n",
    "print(\"Detecting market regimes...\")\n",
    "regimes, features, kmeans_model = regime_detector.detect_regimes_kmeans(n_regimes=3)\n",
    "\n",
    "# Analyze regime characteristics\n",
    "regime_analysis = regime_detector.analyze_regime_characteristics(regimes, features)\n",
    "\n",
    "print(\"\\nMARKET REGIME ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(regime_analysis.round(4))\n",
    "\n",
    "# Label regimes based on characteristics\n",
    "regime_labels = {}\n",
    "for idx, row in regime_analysis.iterrows():\n",
    "    if row['avg_volatility'] > regime_analysis['avg_volatility'].mean():\n",
    "        if row['avg_return'] > 0:\n",
    "            label = 'High Vol Bull'\n",
    "        else:\n",
    "            label = 'High Vol Bear'\n",
    "    else:\n",
    "        if row['avg_return'] > 0:\n",
    "            label = 'Low Vol Bull'\n",
    "        else:\n",
    "            label = 'Low Vol Bear'\n",
    "    \n",
    "    regime_num = int(idx.split('_')[1])\n",
    "    regime_labels[regime_num] = label\n",
    "\n",
    "print(f\"\\nRegime Labels: {regime_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regime detection results\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "fig.suptitle('Market Regime Detection Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Portfolio returns with regime coloring\n",
    "ax1 = axes[0]\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "for regime in regimes.unique():\n",
    "    regime_mask = regimes == regime\n",
    "    regime_dates = regimes[regime_mask].index\n",
    "    regime_values = cumulative_returns[regime_dates]\n",
    "    \n",
    "    ax1.scatter(regime_dates, regime_values, \n",
    "               label=f'{regime_labels.get(regime, f\"Regime {regime}\")}',\n",
    "               alpha=0.7, s=10)\n",
    "\n",
    "ax1.set_title('Portfolio Cumulative Returns by Market Regime')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling volatility with regime coloring\n",
    "ax2 = axes[1]\n",
    "rolling_vol = portfolio_returns.rolling(30).std() * np.sqrt(252)\n",
    "\n",
    "for regime in regimes.unique():\n",
    "    regime_mask = regimes == regime\n",
    "    regime_dates = regimes[regime_mask].index\n",
    "    regime_vol = rolling_vol[regime_dates]\n",
    "    \n",
    "    ax2.scatter(regime_dates, regime_vol,\n",
    "               label=f'{regime_labels.get(regime, f\"Regime {regime}\")}',\n",
    "               alpha=0.7, s=10)\n",
    "\n",
    "ax2.set_title('Rolling Volatility by Market Regime')\n",
    "ax2.set_ylabel('Annualized Volatility')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Regime transitions over time\n",
    "ax3 = axes[2]\n",
    "ax3.plot(regimes.index, regimes, linewidth=2, alpha=0.8)\n",
    "ax3.set_title('Market Regime Transitions Over Time')\n",
    "ax3.set_ylabel('Regime')\n",
    "ax3.set_yticks(list(regime_labels.keys()))\n",
    "ax3.set_yticklabels([regime_labels[k] for k in sorted(regime_labels.keys())])\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Regime transition matrix\n",
    "transition_matrix = pd.crosstab(regimes.shift(1), regimes, normalize='index')\n",
    "transition_matrix.index = [regime_labels.get(i, f'Regime {i}') for i in transition_matrix.index]\n",
    "transition_matrix.columns = [regime_labels.get(i, f'Regime {i}') for i in transition_matrix.columns]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(transition_matrix, annot=True, cmap='Blues', fmt='.3f')\n",
    "plt.title('Regime Transition Probability Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('From Regime')\n",
    "plt.xlabel('To Regime')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nREGIME TRANSITION PROBABILITIES\")\n",
    "print(\"=\" * 50)\n",
    "print(transition_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Risk Monitoring System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicRiskMonitor:\n",
    "    \"\"\"\n",
    "    Real-time risk monitoring and alert system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, portfolio_returns, weights, confidence_levels=[0.95, 0.99]):\n",
    "        self.returns = portfolio_returns\n",
    "        self.weights = weights\n",
    "        self.confidence_levels = confidence_levels\n",
    "        self.risk_metrics = {}\n",
    "        \n",
    "    def calculate_dynamic_var(self, window=60, method='historical'):\n",
    "        \"\"\"\n",
    "        Calculate dynamic Value at Risk\n",
    "        \"\"\"\n",
    "        var_results = {}\n",
    "        \n",
    "        for conf_level in self.confidence_levels:\n",
    "            alpha = 1 - conf_level\n",
    "            \n",
    "            if method == 'historical':\n",
    "                var_series = self.returns.rolling(window).quantile(alpha)\n",
    "            elif method == 'parametric':\n",
    "                rolling_mean = self.returns.rolling(window).mean()\n",
    "                rolling_std = self.returns.rolling(window).std()\n",
    "                z_score = stats.norm.ppf(alpha)\n",
    "                var_series = rolling_mean + z_score * rolling_std\n",
    "            elif method == 'ewma':\n",
    "                # Exponentially weighted moving average\n",
    "                ewm_mean = self.returns.ewm(span=window).mean()\n",
    "                ewm_std = self.returns.ewm(span=window).std()\n",
    "                z_score = stats.norm.ppf(alpha)\n",
    "                var_series = ewm_mean + z_score * ewm_std\n",
    "            \n",
    "            var_results[f'VaR_{int(conf_level*100)}'] = var_series\n",
    "        \n",
    "        return pd.DataFrame(var_results)\n",
    "    \n",
    "    def calculate_expected_shortfall(self, window=60):\n",
    "        \"\"\"\n",
    "        Calculate Expected Shortfall (Conditional VaR)\n",
    "        \"\"\"\n",
    "        es_results = {}\n",
    "        \n",
    "        for conf_level in self.confidence_levels:\n",
    "            alpha = 1 - conf_level\n",
    "            \n",
    "            def rolling_es(x):\n",
    "                var_threshold = x.quantile(alpha)\n",
    "                return x[x <= var_threshold].mean()\n",
    "            \n",
    "            es_series = self.returns.rolling(window).apply(rolling_es)\n",
    "            es_results[f'ES_{int(conf_level*100)}'] = es_series\n",
    "        \n",
    "        return pd.DataFrame(es_results)\n",
    "    \n",
    "    def calculate_component_var(self, asset_returns, window=60):\n",
    "        \"\"\"\n",
    "        Calculate component VaR for risk attribution\n",
    "        \"\"\"\n",
    "        weights_series = pd.Series(self.weights)\n",
    "        component_vars = {}\n",
    "        \n",
    "        for date in asset_returns.index[-window:]:\n",
    "            # Get window of returns ending at this date\n",
    "            window_returns = asset_returns.loc[:date].tail(window)\n",
    "            \n",
    "            if len(window_returns) < window:\n",
    "                continue\n",
    "            \n",
    "            # Calculate covariance matrix\n",
    "            cov_matrix = window_returns.cov()\n",
    "            \n",
    "            # Portfolio variance\n",
    "            portfolio_var = np.dot(weights_series.T, np.dot(cov_matrix, weights_series))\n",
    "            portfolio_vol = np.sqrt(portfolio_var)\n",
    "            \n",
    "            # Marginal VaR\n",
    "            marginal_var = np.dot(cov_matrix, weights_series) / portfolio_vol\n",
    "            \n",
    "            # Component VaR\n",
    "            component_var = weights_series * marginal_var\n",
    "            \n",
    "            component_vars[date] = component_var\n",
    "        \n",
    "        return pd.DataFrame(component_vars).T\n",
    "    \n",
    "    def detect_risk_anomalies(self, var_df, threshold_multiplier=2):\n",
    "        \"\"\"\n",
    "        Detect risk anomalies and generate alerts\n",
    "        \"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        for col in var_df.columns:\n",
    "            var_series = var_df[col].dropna()\n",
    "            \n",
    "            # Calculate rolling statistics\n",
    "            rolling_mean = var_series.rolling(30).mean()\n",
    "            rolling_std = var_series.rolling(30).std()\n",
    "            \n",
    "            # Detect anomalies\n",
    "            upper_threshold = rolling_mean + threshold_multiplier * rolling_std\n",
    "            lower_threshold = rolling_mean - threshold_multiplier * rolling_std\n",
    "            \n",
    "            anomalies = var_series[(var_series > upper_threshold) | (var_series < lower_threshold)]\n",
    "            \n",
    "            for date, value in anomalies.items():\n",
    "                alert_type = 'HIGH_RISK' if value > upper_threshold[date] else 'LOW_RISK'\n",
    "                alerts.append({\n",
    "                    'date': date,\n",
    "                    'metric': col,\n",
    "                    'value': value,\n",
    "                    'threshold': upper_threshold[date] if alert_type == 'HIGH_RISK' else lower_threshold[date],\n",
    "                    'alert_type': alert_type,\n",
    "                    'severity': 'HIGH' if abs(value - rolling_mean[date]) > 3 * rolling_std[date] else 'MEDIUM'\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(alerts)\n",
    "\n",
    "# Initialize risk monitor\n",
    "risk_monitor = DynamicRiskMonitor(portfolio_returns, recommended_weights)\n",
    "\n",
    "# Calculate dynamic risk metrics\n",
    "print(\"Calculating dynamic risk metrics...\")\n",
    "var_metrics = risk_monitor.calculate_dynamic_var(window=60, method='ewma')\n",
    "es_metrics = risk_monitor.calculate_expected_shortfall(window=60)\n",
    "component_var = risk_monitor.calculate_component_var(returns, window=60)\n",
    "\n",
    "# Detect risk anomalies\n",
    "risk_alerts = risk_monitor.detect_risk_anomalies(var_metrics)\n",
    "\n",
    "print(f\"\\nRISK MONITORING SUMMARY\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Current VaR (95%): {var_metrics['VaR_95'].iloc[-1]:.4f}\")\n",
    "print(f\"Current VaR (99%): {var_metrics['VaR_99'].iloc[-1]:.4f}\")\n",
    "print(f\"Current ES (95%): {es_metrics['ES_95'].iloc[-1]:.4f}\")\n",
    "print(f\"Current ES (99%): {es_metrics['ES_99'].iloc[-1]:.4f}\")\n",
    "print(f\"Total risk alerts generated: {len(risk_alerts)}\")\n",
    "\n",
    "if len(risk_alerts) > 0:\n",
    "    print(f\"\\nRecent HIGH severity alerts:\")\n",
    "    high_severity = risk_alerts[risk_alerts['severity'] == 'HIGH'].tail(5)\n",
    "    for _, alert in high_severity.iterrows():\n",
    "        print(f\"  {alert['date'].strftime('%Y-%m-%d')}: {alert['metric']} = {alert['value']:.4f} ({alert['alert_type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dynamic risk metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Dynamic Risk Monitoring Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# VaR evolution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(var_metrics.index, var_metrics['VaR_95'], label='VaR 95%', linewidth=2)\n",
    "ax1.plot(var_metrics.index, var_metrics['VaR_99'], label='VaR 99%', linewidth=2)\n",
    "ax1.fill_between(var_metrics.index, var_metrics['VaR_95'], var_metrics['VaR_99'], alpha=0.3)\n",
    "ax1.set_title('Dynamic Value at Risk')\n",
    "ax1.set_ylabel('VaR')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Expected Shortfall\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(es_metrics.index, es_metrics['ES_95'], label='ES 95%', linewidth=2, color='red')\n",
    "ax2.plot(es_metrics.index, es_metrics['ES_99'], label='ES 99%', linewidth=2, color='darkred')\n",
    "ax2.set_title('Expected Shortfall (Conditional VaR)')\n",
    "ax2.set_ylabel('Expected Shortfall')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Component VaR (most recent)\n",
    "ax3 = axes[1, 0]\n",
    "if not component_var.empty:\n",
    "    latest_component_var = component_var.iloc[-1]\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    bars = ax3.bar(latest_component_var.index, latest_component_var.values, color=colors, alpha=0.7)\n",
    "    ax3.set_title('Component VaR (Risk Attribution)')\n",
    "    ax3.set_ylabel('Component VaR')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, latest_component_var.values):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                f'{value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Risk alerts timeline\n",
    "ax4 = axes[1, 1]\n",
    "if len(risk_alerts) > 0:\n",
    "    # Count alerts by date\n",
    "    alert_counts = risk_alerts.groupby(risk_alerts['date'].dt.date).size()\n",
    "    ax4.bar(alert_counts.index, alert_counts.values, alpha=0.7, color='orange')\n",
    "    ax4.set_title('Risk Alerts Timeline')\n",
    "    ax4.set_ylabel('Number of Alerts')\n",
    "    ax4.tick_params(axis='x', rotation=45)\nelse:\n",
    "    ax4.text(0.5, 0.5, 'No Risk Alerts', ha='center', va='center', transform=ax4.transAxes)\n",
    "    ax4.set_title('Risk Alerts Timeline')\n",
    "\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Risk attribution analysis\n",
    "if not component_var.empty:\n",
    "    print(f\"\\nRISK ATTRIBUTION ANALYSIS\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    # Calculate average component VaR\n",
    "    avg_component_var = component_var.mean()\n",
    "    total_component_var = avg_component_var.sum()\n",
    "    \n",
    "    print(f\"Average Component VaR:\")\n",
    "    for asset, comp_var in avg_component_var.items():\n",
    "        percentage = (comp_var / total_component_var) * 100\n",
    "        weight = recommended_weights.get(asset, 0) * 100\n",
    "        print(f\"  {asset}: {comp_var:.6f} ({percentage:.1f}% of total risk, {weight:.1f}% weight)\")\n",
    "    \n",
    "    # Risk concentration analysis\n",
    "    risk_concentration = (avg_component_var / total_component_var).max()\n",
    "    print(f\"\\nRisk Concentration (max single asset): {risk_concentration*100:.1f}%\")\n",
    "    \n",
    "    if risk_concentration > 0.5:\n",
    "        print(\"‚ö†Ô∏è  WARNING: High risk concentration detected!\")\n",
    "    elif risk_concentration > 0.4:\n",
    "        print(\"‚ö†Ô∏è  CAUTION: Moderate risk concentration\")\n",
    "    else:\n",
    "        print(\"‚úÖ Risk is well diversified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Testing and Scenario Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedStressTester:\n",
    "    \"\"\"\n",
    "    Advanced stress testing with multiple scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns_data, weights):\n",
    "        self.returns = returns_data\n",
    "        self.weights = pd.Series(weights)\n",
    "        self.portfolio_returns = (returns_data * self.weights).sum(axis=1)\n",
    "        \n",
    "    def historical_stress_test(self, stress_periods):\n",
    "        \"\"\"\n",
    "        Test portfolio performance during historical stress periods\n",
    "        \"\"\"\n",
    "        stress_results = {}\n",
    "        \n",
    "        for period_name, (start_date, end_date) in stress_periods.items():\n",
    "            period_returns = self.portfolio_returns[\n",
    "                (self.portfolio_returns.index >= start_date) & \n",
    "                (self.portfolio_returns.index <= end_date)\n",
    "            ]\n",
    "            \n",
    "            if len(period_returns) > 0:\n",
    "                cumulative_return = (1 + period_returns).prod() - 1\n",
    "                volatility = period_returns.std() * np.sqrt(252)\n",
    "                max_drawdown = self._calculate_max_drawdown(period_returns)\n",
    "                worst_day = period_returns.min()\n",
    "                \n",
    "                stress_results[period_name] = {\n",
    "                    'cumulative_return': cumulative_return,\n",
    "                    'volatility': volatility,\n",
    "                    'max_drawdown': max_drawdown,\n",
    "                    'worst_day': worst_day,\n",
    "                    'days': len(period_returns)\n",
    "                }\n",
    "        \n",
    "        return pd.DataFrame(stress_results).T\n",
    "    \n",
    "    def monte_carlo_stress_test(self, scenarios, n_simulations=10000):\n",
    "        \"\"\"\n",
    "        Monte Carlo stress testing with custom scenarios\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for scenario_name, scenario_params in scenarios.items():\n",
    "            # Extract scenario parameters\n",
    "            asset_shocks = scenario_params.get('asset_shocks', {})\n",
    "            correlation_shock = scenario_params.get('correlation_shock', 0)\n",
    "            volatility_multiplier = scenario_params.get('volatility_multiplier', 1)\n",
    "            \n",
    "            # Base statistics\n",
    "            base_returns = self.returns.mean()\n",
    "            base_cov = self.returns.cov()\n",
    "            \n",
    "            # Apply shocks\n",
    "            shocked_returns = base_returns.copy()\n",
    "            for asset, shock in asset_shocks.items():\n",
    "                if asset in shocked_returns.index:\n",
    "                    shocked_returns[asset] += shock\n",
    "            \n",
    "            # Modify covariance matrix\n",
    "            shocked_cov = base_cov * volatility_multiplier\n",
    "            \n",
    "            if correlation_shock != 0:\n",
    "                # Increase correlations\n",
    "                corr_matrix = base_cov.corr()\n",
    "                vol_matrix = np.sqrt(np.diag(base_cov))\n",
    "                \n",
    "                # Shock correlations\n",
    "                shocked_corr = corr_matrix + correlation_shock\n",
    "                shocked_corr = np.clip(shocked_corr, -0.99, 0.99)\n",
    "                np.fill_diagonal(shocked_corr, 1)\n",
    "                \n",
    "                # Reconstruct covariance matrix\n",
    "                shocked_cov = np.outer(vol_matrix, vol_matrix) * shocked_corr\n",
    "                shocked_cov = pd.DataFrame(shocked_cov, index=base_cov.index, columns=base_cov.columns)\n",
    "            \n",
    "            # Monte Carlo simulation\n",
    "            np.random.seed(42)\n",
    "            simulated_returns = np.random.multivariate_normal(\n",
    "                shocked_returns.values, shocked_cov.values, n_simulations\n",
    "            )\n",
    "            \n",
    "            # Calculate portfolio returns\n",
    "            portfolio_sim_returns = np.dot(simulated_returns, self.weights.values)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            results[scenario_name] = {\n",
    "                'mean_return': np.mean(portfolio_sim_returns),\n",
    "                'volatility': np.std(portfolio_sim_returns),\n",
    "                'var_95': np.percentile(portfolio_sim_returns, 5),\n",
    "                'var_99': np.percentile(portfolio_sim_returns, 1),\n",
    "                'expected_shortfall_95': np.mean(portfolio_sim_returns[portfolio_sim_returns <= np.percentile(portfolio_sim_returns, 5)]),\n",
    "                'worst_case': np.min(portfolio_sim_returns),\n",
    "                'probability_loss': np.mean(portfolio_sim_returns < 0) * 100\n",
    "            }\n",
    "        \n",
    "        return pd.DataFrame(results).T\n",
    "    \n",
    "    def _calculate_max_drawdown(self, returns_series):\n",
    "        \"\"\"\n",
    "        Calculate maximum drawdown\n",
    "        \"\"\"\n",
    "        cumulative = (1 + returns_series).cumprod()\n",
    "        rolling_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - rolling_max) / rolling_max\n",
    "        return drawdown.min()\n",
    "\n",
    "# Initialize stress tester\n",
    "stress_tester = AdvancedStressTester(returns, recommended_weights)\n",
    "\n",
    "# Define historical stress periods\n",
    "stress_periods = {\n",
    "    'COVID-19 Crash': ('2020-02-20', '2020-04-30'),\n",
    "    'December 2018 Selloff': ('2018-10-01', '2018-12-31'),\n",
    "    'Early 2022 Correction': ('2022-01-01', '2022-06-30'),\n",
    "    'August 2015 Flash Crash': ('2015-08-01', '2015-09-30')\n",
    "}\n",
    "\n",
    "# Run historical stress tests\n",
    "print(\"Running historical stress tests...\")\n",
    "historical_stress = stress_tester.historical_stress_test(stress_periods)\n",
    "\n",
    "print(\"\\nHISTORICAL STRESS TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(historical_stress.round(4))\n",
    "\n",
    "# Define Monte Carlo scenarios\n",
    "mc_scenarios = {\n",
    "    'Market Crash': {\n",
    "        'asset_shocks': {'TSLA': -0.3, 'SPY': -0.2, 'BND': 0.05},\n",
    "        'correlation_shock': 0.3,\n",
    "        'volatility_multiplier': 2.0\n",
    "    },\n",
    "    'Interest Rate Shock': {\n",
    "        'asset_shocks': {'BND': -0.15, 'SPY': -0.1, 'TSLA': -0.05},\n",
    "        'correlation_shock': 0.2,\n",
    "        'volatility_multiplier': 1.5\n",
    "    },\n",
    "    'Tech Bubble Burst': {\n",
    "        'asset_shocks': {'TSLA': -0.5, 'SPY': -0.15, 'BND': 0.1},\n",
    "        'correlation_shock': 0.1,\n",
    "        'volatility_multiplier': 2.5\n",
    "    },\n",
    "    'Stagflation': {\n",
    "        'asset_shocks': {'TSLA': -0.1, 'SPY': -0.1, 'BND': -0.2},\n",
    "        'correlation_shock': 0.4,\n",
    "        'volatility_multiplier': 1.8\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run Monte Carlo stress tests\n",
    "print(\"\\nRunning Monte Carlo stress tests...\")\n",
    "mc_stress = stress_tester.monte_carlo_stress_test(mc_scenarios)\n",
    "\n",
    "print(\"\\nMONTE CARLO STRESS TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(mc_stress.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stress test results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Advanced Stress Testing Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Historical stress test - cumulative returns\n",
    "ax1 = axes[0, 0]\n",
    "historical_stress['cumulative_return'].plot(kind='bar', ax=ax1, color='red', alpha=0.7)\n",
    "ax1.set_title('Historical Stress Periods - Cumulative Returns')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Historical stress test - max drawdown\n",
    "ax2 = axes[0, 1]\n",
    "historical_stress['max_drawdown'].plot(kind='bar', ax=ax2, color='darkred', alpha=0.7)\n",
    "ax2.set_title('Historical Stress Periods - Maximum Drawdown')\n",
    "ax2.set_ylabel('Maximum Drawdown')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Monte Carlo stress test - VaR comparison\n",
    "ax3 = axes[1, 0]\n",
    "var_comparison = mc_stress[['var_95', 'var_99']]\n",
    "var_comparison.plot(kind='bar', ax=ax3, alpha=0.7)\n",
    "ax3.set_title('Monte Carlo Scenarios - VaR Comparison')\n",
    "ax3.set_ylabel('Value at Risk')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.legend(['VaR 95%', 'VaR 99%'])\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Monte Carlo stress test - probability of loss\n",
    "ax4 = axes[1, 1]\n",
    "mc_stress['probability_loss'].plot(kind='bar', ax=ax4, color='orange', alpha=0.7)\n",
    "ax4.set_title('Monte Carlo Scenarios - Probability of Loss')\n",
    "ax4.set_ylabel('Probability of Loss (%)')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stress test summary and recommendations\n",
    "print(f\"\\nSTRESS TEST SUMMARY AND RECOMMENDATIONS\")\n",
    "print(f\"=\" * 60)\n",
    "\n",
    "# Worst historical performance\n",
    "worst_historical = historical_stress['cumulative_return'].min()\n",
    "worst_period = historical_stress['cumulative_return'].idxmin()\n",
    "print(f\"Worst historical performance: {worst_historical:.2%} during {worst_period}\")\n",
    "\n",
    "# Worst Monte Carlo scenario\n",
    "worst_mc_scenario = mc_stress['var_99'].idxmin()\n",
    "worst_mc_var = mc_stress.loc[worst_mc_scenario, 'var_99']\n",
    "print(f\"Worst Monte Carlo scenario: {worst_mc_scenario} (VaR 99%: {worst_mc_var:.2%})\")\n",
    "\n",
    "# Risk recommendations\n",
    "print(f\"\\nRISK MANAGEMENT RECOMMENDATIONS:\")\n",
    "print(f\"-\" * 40)\n",
    "\n",
    "if worst_historical < -0.3:\n",
    "    print(\"üî¥ HIGH RISK: Portfolio showed severe losses during historical stress periods\")\n",
    "    print(\"   ‚Üí Consider reducing allocation to high-volatility assets\")\n",
    "    print(\"   ‚Üí Implement dynamic hedging strategies\")\nelif worst_historical < -0.15:\n",
    "    print(\"üü° MEDIUM RISK: Portfolio showed moderate stress during crisis periods\")\n",
    "    print(\"   ‚Üí Monitor risk metrics closely during market volatility\")\n",
    "    print(\"   ‚Üí Consider partial hedging during high-risk periods\")\nelse:\n",
    "    print(\"üü¢ LOW RISK: Portfolio demonstrated resilience during historical stress periods\")\n",
    "    print(\"   ‚Üí Continue current risk management approach\")\n",
    "\n",
    "# Scenario-specific recommendations\n",
    "high_loss_prob_scenarios = mc_stress[mc_stress['probability_loss'] > 60]\n",
    "if not high_loss_prob_scenarios.empty:\n",
    "    print(f\"\\n‚ö†Ô∏è  High loss probability scenarios detected:\")\n",
    "    for scenario in high_loss_prob_scenarios.index:\n",
    "        prob = high_loss_prob_scenarios.loc[scenario, 'probability_loss']\n",
    "        print(f\"   ‚Üí {scenario}: {prob:.1f}% probability of loss\")\n",
    "\n",
    "print(f\"\\nGeneral Recommendations:\")\n",
    "print(f\"‚Ä¢ Implement stop-loss orders at portfolio level\")\n",
    "print(f\"‚Ä¢ Consider tail risk hedging instruments\")\n",
    "print(f\"‚Ä¢ Regular stress testing (monthly)\")\n",
    "print(f\"‚Ä¢ Dynamic position sizing based on market regime\")\n",
    "print(f\"‚Ä¢ Maintain adequate cash reserves for rebalancing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Management Summary and Action Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive risk management summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE RISK MANAGEMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. CURRENT RISK PROFILE:\")\n",
    "print(f\"-\" * 40)\n",
    "current_var_95 = var_metrics['VaR_95'].iloc[-1]\n",
    "current_var_99 = var_metrics['VaR_99'].iloc[-1]\n",
    "current_es_95 = es_metrics['ES_95'].iloc[-1]\n",
    "\n",
    "print(f\"‚Ä¢ Daily VaR (95%): {current_var_95:.2%}\")\n",
    "print(f\"‚Ä¢ Daily VaR (99%): {current_var_99:.2%}\")\n",
    "print(f\"‚Ä¢ Expected Shortfall (95%): {current_es_95:.2%}\")\n",
    "print(f\"‚Ä¢ Portfolio Volatility: {portfolio_returns.std() * np.sqrt(252):.2%}\")\n",
    "\n",
    "print(f\"\\n2. MARKET REGIME ANALYSIS:\")\n",
    "print(f\"-\" * 40)\n",
    "current_regime = regimes.iloc[-1]\n",
    "current_regime_label = regime_labels.get(current_regime, f'Regime {current_regime}')\n",
    "print(f\"‚Ä¢ Current Market Regime: {current_regime_label}\")\n",
    "\n",
    "# Regime stability\n",
    "recent_regimes = regimes.tail(30)  # Last 30 days\n",
    "regime_changes = (recent_regimes != recent_regimes.shift(1)).sum()\n",
    "print(f\"‚Ä¢ Regime Changes (last 30 days): {regime_changes}\")\n",
    "print(f\"‚Ä¢ Regime Stability: {'High' if regime_changes <= 2 else 'Medium' if regime_changes <= 5 else 'Low'}\")\n",
    "\n",
    "print(f\"\\n3. STRESS TEST INSIGHTS:\")\n",
    "print(f\"-\" * 40)\n",
    "avg_historical_loss = historical_stress['cumulative_return'].mean()\n",
    "worst_historical_loss = historical_stress['cumulative_return'].min()\n",
    "avg_mc_var_99 = mc_stress['var_99'].mean()\n",
    "\n",
    "print(f\"‚Ä¢ Average Historical Stress Loss: {avg_historical_loss:.2%}\")\n",
    "print(f\"‚Ä¢ Worst Historical Stress Loss: {worst_historical_loss:.2%}\")\n",
    "print(f\"‚Ä¢ Average Monte Carlo VaR (99%): {avg_mc_var_99:.2%}\")\n",
    "\n",
    "print(f\"\\n4. RISK CONCENTRATION:\")\n",
    "print(f\"-\" * 40)\n",
    "if not component_var.empty:\n",
    "    latest_component_var = component_var.iloc[-1]\n",
    "    max_risk_asset = latest_component_var.abs().idxmax()\n",
    "    max_risk_contribution = latest_component_var.abs().max() / latest_component_var.abs().sum()\n",
    "    \n",
    "    print(f\"‚Ä¢ Highest Risk Contributor: {max_risk_asset}\")\n",
    "    print(f\"‚Ä¢ Maximum Risk Concentration: {max_risk_contribution:.1%}\")\n",
    "    \n",
    "    risk_level = \"High\" if max_risk_contribution > 0.6 else \"Medium\" if max_risk_contribution > 0.4 else \"Low\"\n",
    "    print(f\"‚Ä¢ Risk Concentration Level: {risk_level}\")\n",
    "\n",
    "print(f\"\\n5. ALERT SYSTEM STATUS:\")\n",
    "print(f\"-\" * 40)\n",
    "total_alerts = len(risk_alerts)\n",
    "high_severity_alerts = len(risk_alerts[risk_alerts['severity'] == 'HIGH']) if len(risk_alerts) > 0 else 0\n",
    "recent_alerts = len(risk_alerts[risk_alerts['date'] >= (datetime.now() - timedelta(days=7))]) if len(risk_alerts) > 0 else 0\n",
    "\n",
    "print(f\"‚Ä¢ Total Risk Alerts: {total_alerts}\")\n",
    "print(f\"‚Ä¢ High Severity Alerts: {high_severity_alerts}\")\n",
    "print(f\"‚Ä¢ Recent Alerts (7 days): {recent_alerts}\")\n",
    "\n",
    "alert_status = \"Critical\" if high_severity_alerts > 5 else \"Warning\" if recent_alerts > 3 else \"Normal\"\n",
    "print(f\"‚Ä¢ Alert System Status: {alert_status}\")\n",
    "\n",
    "print(f\"\\n6. RECOMMENDED ACTIONS:\")\n",
    "print(f\"-\" * 40)\n",
    "\n",
    "# Generate specific recommendations based on analysis\n",
    "recommendations = []\n",
    "\n",
    "# VaR-based recommendations\n",
    "if abs(current_var_99) > 0.05:  # 5% daily VaR\n",
    "    recommendations.append(\"üî¥ URGENT: Daily VaR exceeds 5% - consider immediate position reduction\")\nelif abs(current_var_99) > 0.03:  # 3% daily VaR\n",
    "    recommendations.append(\"üü° CAUTION: Daily VaR elevated - monitor closely and prepare for position adjustment\")\n\n# Regime-based recommendations\nif regime_changes > 5:\n    recommendations.append(\"‚ö†Ô∏è  High regime instability - implement dynamic hedging\")\n\n# Stress test recommendations\nif worst_historical_loss < -0.3:\n    recommendations.append(\"üìâ Historical stress tests show severe losses - diversify further\")\n\n# Risk concentration recommendations\nif not component_var.empty and max_risk_contribution > 0.6:\n    recommendations.append(f\"‚öñÔ∏è  High risk concentration in {max_risk_asset} - rebalance portfolio\")\n\n# Alert-based recommendations\nif alert_status == \"Critical\":\n    recommendations.append(\"üö® Critical alert status - immediate risk review required\")\nelif alert_status == \"Warning\":\n    recommendations.append(\"‚ö†Ô∏è  Warning alert status - enhanced monitoring recommended\")\n\n# Default recommendations if no specific issues\nif not recommendations:\n    recommendations = [\n        \"‚úÖ Risk profile within acceptable parameters\",\n        \"üìä Continue regular monitoring and monthly stress testing\",\n        \"üîÑ Maintain current rebalancing schedule\"\n    ]\n\nfor i, rec in enumerate(recommendations, 1):\n    print(f\"{i}. {rec}\")\n\nprint(f\"\\n7. MONITORING SCHEDULE:\")\nprint(f\"-\" * 40)\nprint(f\"‚Ä¢ Daily: VaR and portfolio returns monitoring\")\nprint(f\"‚Ä¢ Weekly: Risk alert review and regime analysis\")\nprint(f\"‚Ä¢ Monthly: Comprehensive stress testing\")\nprint(f\"‚Ä¢ Quarterly: Risk model validation and recalibration\")\nprint(f\"‚Ä¢ Semi-annually: Portfolio optimization review\")\n\nprint(f\"\\n8. EMERGENCY PROCEDURES:\")\nprint(f\"-\" * 40)\nprint(f\"‚Ä¢ VaR > 5%: Immediate position review and potential reduction\")\nprint(f\"‚Ä¢ Multiple high-severity alerts: Emergency risk committee meeting\")\nprint(f\"‚Ä¢ Regime change: Reassess portfolio allocation within 48 hours\")\nprint(f\"‚Ä¢ Stress test failure: Implement contingency hedging strategies\")\n\nprint(f\"\\n\" + \"=\"*80)\nprint(\"RISK MANAGEMENT ANALYSIS COMPLETE\")\nprint(\"=\"*80)\n\n# Save risk management results\nrisk_management_summary = {\n    'current_risk_metrics': {\n        'var_95': current_var_95,\n        'var_99': current_var_99,\n        'expected_shortfall_95': current_es_95,\n        'portfolio_volatility': portfolio_returns.std() * np.sqrt(252)\n    },\n    'regime_analysis': {\n        'current_regime': current_regime_label,\n        'regime_stability': 'High' if regime_changes <= 2 else 'Medium' if regime_changes <= 5 else 'Low',\n        'recent_changes': int(regime_changes)\n    },\n    'stress_test_summary': {\n        'worst_historical_loss': worst_historical_loss,\n        'average_mc_var_99': avg_mc_var_99\n    },\n    'alert_status': alert_status,\n    'recommendations': recommendations\n}\n\nwith open('../data/risk_management_summary.pkl', 'wb') as f:\n    pickle.dump(risk_management_summary, f)\n\nprint(\"\\nRisk management summary saved to '../data/risk_management_summary.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
