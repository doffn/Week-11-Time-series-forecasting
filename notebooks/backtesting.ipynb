{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Backtesting and Performance Analysis\n",
    "\n",
    "This notebook covers:\n",
    "- Historical backtesting of optimized portfolios\n",
    "- Performance attribution analysis\n",
    "- Risk-adjusted performance metrics\n",
    "- Comparison with benchmark portfolios\n",
    "- Sensitivity analysis and stress testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Performance analysis libraries\n",
    "from scipy import stats\n",
    "import empyrical as ep\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Custom modules\n",
    "from src.data.loader import DataLoader\n",
    "from src.backtesting.engine import BacktestEngine\n",
    "from src.utils.logger import setup_logger\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = setup_logger(__name__)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Backtesting libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Portfolio Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load market data\n",
    "loader = DataLoader()\n",
    "data = loader.load_data(['TSLA', 'BND', 'SPY'], '2015-07-01', '2025-07-31')\n",
    "prices = data['prices']\n",
    "returns = data['returns']\n",
    "\n",
    "# Load portfolio recommendation\n",
    "try:\n",
    "    with open('../data/portfolio_recommendation.pkl', 'rb') as f:\n",
    "        portfolio_rec = pickle.load(f)\n",
    "    print(\"✓ Portfolio recommendation loaded\")\n",
    "    \n",
    "    print(f\"\\nRecommended Strategy: {portfolio_rec['strategy']}\")\n",
    "    print(f\"Expected Return: {portfolio_rec['expected_return']*100:.2f}%\")\n",
    "    print(f\"Expected Volatility: {portfolio_rec['expected_volatility']*100:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {portfolio_rec['sharpe_ratio']:.3f}\")\n",
    "    \n",
    "    recommended_weights = portfolio_rec['weights']\n",
    "    print(f\"\\nWeights:\")\n",
    "    for asset, weight in recommended_weights.items():\n",
    "        print(f\"  {asset}: {weight*100:.2f}%\")\n",
    "        \nexcept FileNotFoundError:\n",
    "    print(\"✗ Portfolio recommendation not found. Using default weights.\")\n",
    "    recommended_weights = {'TSLA': 0.4, 'BND': 0.3, 'SPY': 0.3}\n",
    "    portfolio_rec = None\n",
    "\n",
    "# Asset information\n",
    "assets = ['TSLA', 'BND', 'SPY']\n",
    "print(f\"\\nBacktesting period: {prices.index.min()} to {prices.index.max()}\")\n",
    "print(f\"Total observations: {len(prices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting Framework Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioBacktester:\n",
    "    \"\"\"\n",
    "    Comprehensive portfolio backtesting framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prices_data, returns_data, initial_capital=100000):\n",
    "        self.prices = prices_data\n",
    "        self.returns = returns_data\n",
    "        self.initial_capital = initial_capital\n",
    "        self.assets = list(prices_data.columns)\n",
    "        \n",
    "    def calculate_portfolio_returns(self, weights, rebalance_freq='M'):\n",
    "        \"\"\"\n",
    "        Calculate portfolio returns with rebalancing\n",
    "        \"\"\"\n",
    "        # Convert weights to pandas Series if dict\n",
    "        if isinstance(weights, dict):\n",
    "            weights = pd.Series(weights)\n",
    "        \n",
    "        # Align weights with assets\n",
    "        weights = weights.reindex(self.assets, fill_value=0)\n",
    "        \n",
    "        if rebalance_freq == 'B':  # Buy and hold\n",
    "            # Simple buy and hold strategy\n",
    "            portfolio_returns = (self.returns * weights).sum(axis=1)\n",
    "        else:\n",
    "            # Rebalancing strategy\n",
    "            portfolio_returns = []\n",
    "            current_weights = weights.copy()\n",
    "            \n",
    "            # Group by rebalancing frequency\n",
    "            grouped = self.returns.groupby(pd.Grouper(freq=rebalance_freq))\n",
    "            \n",
    "            for period, period_returns in grouped:\n",
    "                if len(period_returns) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate returns for this period\n",
    "                period_portfolio_returns = (period_returns * current_weights).sum(axis=1)\n",
    "                portfolio_returns.extend(period_portfolio_returns.tolist())\n",
    "                \n",
    "                # Rebalance at end of period (reset to target weights)\n",
    "                current_weights = weights.copy()\n",
    "            \n",
    "            portfolio_returns = pd.Series(portfolio_returns, index=self.returns.index[:len(portfolio_returns)])\n",
    "        \n",
    "        return portfolio_returns\n",
    "    \n",
    "    def calculate_performance_metrics(self, portfolio_returns, benchmark_returns=None, risk_free_rate=0.02):\n",
    "        \"\"\"\n",
    "        Calculate comprehensive performance metrics\n",
    "        \"\"\"\n",
    "        # Basic metrics\n",
    "        total_return = (1 + portfolio_returns).prod() - 1\n",
    "        annualized_return = (1 + total_return) ** (252 / len(portfolio_returns)) - 1\n",
    "        annualized_volatility = portfolio_returns.std() * np.sqrt(252)\n",
    "        \n",
    "        # Risk-adjusted metrics\n",
    "        sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility\n",
    "        \n",
    "        # Drawdown analysis\n",
    "        cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "        rolling_max = cumulative_returns.expanding().max()\n",
    "        drawdown = (cumulative_returns - rolling_max) / rolling_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Calmar ratio\n",
    "        calmar_ratio = annualized_return / abs(max_drawdown) if max_drawdown != 0 else np.inf\n",
    "        \n",
    "        # VaR and CVaR\n",
    "        var_95 = np.percentile(portfolio_returns, 5)\n",
    "        var_99 = np.percentile(portfolio_returns, 1)\n",
    "        cvar_95 = portfolio_returns[portfolio_returns <= var_95].mean()\n",
    "        cvar_99 = portfolio_returns[portfolio_returns <= var_99].mean()\n",
    "        \n",
    "        # Skewness and Kurtosis\n",
    "        skewness = portfolio_returns.skew()\n",
    "        kurtosis = portfolio_returns.kurtosis()\n",
    "        \n",
    "        # Win rate\n",
    "        win_rate = (portfolio_returns > 0).mean()\n",
    "        \n",
    "        metrics = {\n",
    "            'Total Return': total_return,\n",
    "            'Annualized Return': annualized_return,\n",
    "            'Annualized Volatility': annualized_volatility,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Max Drawdown': max_drawdown,\n",
    "            'Calmar Ratio': calmar_ratio,\n",
    "            'VaR 95%': var_95,\n",
    "            'VaR 99%': var_99,\n",
    "            'CVaR 95%': cvar_95,\n",
    "            'CVaR 99%': cvar_99,\n",
    "            'Skewness': skewness,\n",
    "            'Kurtosis': kurtosis,\n",
    "            'Win Rate': win_rate\n",
    "        }\n",
    "        \n",
    "        # Benchmark comparison if provided\n",
    "        if benchmark_returns is not None:\n",
    "            # Align returns\n",
    "            aligned_portfolio, aligned_benchmark = portfolio_returns.align(benchmark_returns, join='inner')\n",
    "            \n",
    "            # Information ratio\n",
    "            excess_returns = aligned_portfolio - aligned_benchmark\n",
    "            information_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)\n",
    "            \n",
    "            # Beta and Alpha\n",
    "            covariance = np.cov(aligned_portfolio, aligned_benchmark)[0, 1]\n",
    "            benchmark_variance = aligned_benchmark.var()\n",
    "            beta = covariance / benchmark_variance\n",
    "            \n",
    "            benchmark_annual_return = (1 + aligned_benchmark).prod() ** (252 / len(aligned_benchmark)) - 1\n",
    "            alpha = annualized_return - (risk_free_rate + beta * (benchmark_annual_return - risk_free_rate))\n",
    "            \n",
    "            # Tracking error\n",
    "            tracking_error = excess_returns.std() * np.sqrt(252)\n",
    "            \n",
    "            metrics.update({\n",
    "                'Information Ratio': information_ratio,\n",
    "                'Beta': beta,\n",
    "                'Alpha': alpha,\n",
    "                'Tracking Error': tracking_error\n",
    "            })\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def rolling_performance(self, portfolio_returns, window=252):\n",
    "        \"\"\"\n",
    "        Calculate rolling performance metrics\n",
    "        \"\"\"\n",
    "        rolling_return = portfolio_returns.rolling(window).apply(lambda x: (1 + x).prod() - 1)\n",
    "        rolling_volatility = portfolio_returns.rolling(window).std() * np.sqrt(252)\n",
    "        rolling_sharpe = (rolling_return * 252 / window - 0.02) / rolling_volatility\n",
    "        \n",
    "        return {\n",
    "            'rolling_return': rolling_return,\n",
    "            'rolling_volatility': rolling_volatility,\n",
    "            'rolling_sharpe': rolling_sharpe\n",
    "        }\n",
    "\n",
    "# Initialize backtester\n",
    "backtester = PortfolioBacktester(prices, returns)\n",
    "print(\"Backtesting framework initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Strategy Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define portfolio strategies to backtest\n",
    "strategies = {\n",
    "    'Optimized Portfolio': recommended_weights,\n",
    "    'Equal Weight': {'TSLA': 1/3, 'BND': 1/3, 'SPY': 1/3},\n",
    "    '60/40 Traditional': {'TSLA': 0.0, 'BND': 0.4, 'SPY': 0.6},\n",
    "    'Conservative': {'TSLA': 0.1, 'BND': 0.6, 'SPY': 0.3},\n",
    "    'Aggressive': {'TSLA': 0.6, 'BND': 0.1, 'SPY': 0.3}\n",
    "}\n",
    "\n",
    "# Backtest all strategies\n",
    "backtest_results = {}\n",
    "rebalance_frequency = 'M'  # Monthly rebalancing\n",
    "\n",
    "print(\"BACKTESTING PORTFOLIO STRATEGIES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Rebalancing Frequency: {rebalance_frequency}\")\n",
    "print(f\"Backtesting Period: {returns.index.min()} to {returns.index.max()}\")\n",
    "\n",
    "for strategy_name, weights in strategies.items():\n",
    "    print(f\"\\nBacktesting {strategy_name}...\")\n",
    "    \n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = backtester.calculate_portfolio_returns(weights, rebalance_frequency)\n",
    "    \n",
    "    # Use SPY as benchmark\n",
    "    benchmark_returns = returns['SPY']\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    metrics = backtester.calculate_performance_metrics(\n",
    "        portfolio_returns, benchmark_returns\n",
    "    )\n",
    "    \n",
    "    # Calculate rolling metrics\n",
    "    rolling_metrics = backtester.rolling_performance(portfolio_returns)\n",
    "    \n",
    "    # Store results\n",
    "    backtest_results[strategy_name] = {\n",
    "        'returns': portfolio_returns,\n",
    "        'metrics': metrics,\n",
    "        'rolling': rolling_metrics,\n",
    "        'weights': weights\n",
    "    }\n",
    "    \n",
    "    print(f\"  Total Return: {metrics['Total Return']*100:.2f}%\")\n",
    "    print(f\"  Annualized Return: {metrics['Annualized Return']*100:.2f}%\")\n",
    "    print(f\"  Volatility: {metrics['Annualized Volatility']*100:.2f}%\")\n",
    "    print(f\"  Sharpe Ratio: {metrics['Sharpe Ratio']:.3f}\")\n",
    "    print(f\"  Max Drawdown: {metrics['Max Drawdown']*100:.2f}%\")\n",
    "\n",
    "print(\"\\nBacktesting completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison\n",
    "performance_data = []\n",
    "\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    metrics = results['metrics']\n",
    "    row = [\n",
    "        strategy_name,\n",
    "        metrics['Total Return'] * 100,\n",
    "        metrics['Annualized Return'] * 100,\n",
    "        metrics['Annualized Volatility'] * 100,\n",
    "        metrics['Sharpe Ratio'],\n",
    "        metrics['Max Drawdown'] * 100,\n",
    "        metrics['Calmar Ratio'],\n",
    "        metrics['Information Ratio'],\n",
    "        metrics['Beta'],\n",
    "        metrics['Alpha'] * 100,\n",
    "        metrics['Win Rate'] * 100\n",
    "    ]\n",
    "    performance_data.append(row)\n",
    "\n",
    "columns = [\n",
    "    'Strategy', 'Total Return (%)', 'Annual Return (%)', 'Volatility (%)',\n",
    "    'Sharpe Ratio', 'Max Drawdown (%)', 'Calmar Ratio', 'Information Ratio',\n",
    "    'Beta', 'Alpha (%)', 'Win Rate (%)'\n",
    "]\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data, columns=columns)\n",
    "performance_df = performance_df.sort_values('Sharpe Ratio', ascending=False)\n",
    "\n",
    "print(\"COMPREHENSIVE PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "print(performance_df.round(3).to_string(index=False))\n",
    "\n",
    "# Identify best performing strategy\n",
    "best_strategy = performance_df.iloc[0]['Strategy']\n",
    "print(f\"\\nBest Performing Strategy (by Sharpe Ratio): {best_strategy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Portfolio Strategy Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Cumulative Returns\n",
    "ax1 = axes[0, 0]\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    cumulative_returns = (1 + results['returns']).cumprod()\n",
    "    ax1.plot(cumulative_returns.index, cumulative_returns, \n",
    "             label=strategy_name, linewidth=2)\n",
    "\n",
    "ax1.set_title('Cumulative Returns')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# 2. Risk-Return Scatter\n",
    "ax2 = axes[0, 1]\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    metrics = results['metrics']\n",
    "    ax2.scatter(metrics['Annualized Volatility']*100, \n",
    "               metrics['Annualized Return']*100,\n",
    "               s=100, label=strategy_name)\n",
    "\n",
    "ax2.set_xlabel('Volatility (%)')\n",
    "ax2.set_ylabel('Annual Return (%)')\n",
    "ax2.set_title('Risk-Return Profile')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Drawdown Analysis\n",
    "ax3 = axes[0, 2]\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    portfolio_returns = results['returns']\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "    rolling_max = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns - rolling_max) / rolling_max\n",
    "    \n",
    "    ax3.fill_between(drawdown.index, drawdown*100, 0, alpha=0.7, label=strategy_name)\n",
    "\n",
    "ax3.set_title('Drawdown Analysis')\n",
    "ax3.set_ylabel('Drawdown (%)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Rolling Sharpe Ratio\n",
    "ax4 = axes[1, 0]\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    rolling_sharpe = results['rolling']['rolling_sharpe']\n",
    "    ax4.plot(rolling_sharpe.index, rolling_sharpe, \n",
    "             label=strategy_name, linewidth=2, alpha=0.8)\n",
    "\n",
    "ax4.set_title('Rolling Sharpe Ratio (1-Year)')\n",
    "ax4.set_ylabel('Sharpe Ratio')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Performance Metrics Bar Chart\n",
    "ax5 = axes[1, 1]\n",
    "metrics_to_plot = ['Sharpe Ratio', 'Calmar Ratio', 'Information Ratio']\n",
    "x = np.arange(len(strategies))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    values = [backtest_results[strategy]['metrics'][metric] for strategy in strategies.keys()]\n",
    "    ax5.bar(x + i*width, values, width, label=metric, alpha=0.8)\n",
    "\n",
    "ax5.set_xlabel('Strategy')\n",
    "ax5.set_ylabel('Ratio')\n",
    "ax5.set_title('Risk-Adjusted Performance Metrics')\n",
    "ax5.set_xticks(x + width)\n",
    "ax5.set_xticklabels(list(strategies.keys()), rotation=45, ha='right')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Return Distribution\n",
    "ax6 = axes[1, 2]\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    portfolio_returns = results['returns']\n",
    "    ax6.hist(portfolio_returns*100, bins=50, alpha=0.6, label=strategy_name, density=True)\n",
    "\n",
    "ax6.set_xlabel('Daily Returns (%)')\n",
    "ax6.set_ylabel('Density')\n",
    "ax6.set_title('Return Distribution')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Based Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance by different time periods\n",
    "def analyze_period_performance(returns_series, start_date, end_date, period_name):\n",
    "    \"\"\"\n",
    "    Analyze performance for a specific time period\n",
    "    \"\"\"\n",
    "    period_returns = returns_series[(returns_series.index >= start_date) & \n",
    "                                   (returns_series.index <= end_date)]\n",
    "    \n",
    "    if len(period_returns) == 0:\n",
    "        return None\n",
    "    \n",
    "    total_return = (1 + period_returns).prod() - 1\n",
    "    volatility = period_returns.std() * np.sqrt(252)\n",
    "    sharpe = (total_return * 252 / len(period_returns) - 0.02) / volatility\n",
    "    max_dd = ((1 + period_returns).cumprod() / (1 + period_returns).cumprod().expanding().max() - 1).min()\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Total Return': total_return * 100,\n",
    "        'Volatility': volatility * 100,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown': max_dd * 100\n",
    "    }\n",
    "\n",
    "# Define analysis periods\n",
    "analysis_periods = [\n",
    "    ('2015-07-01', '2017-12-31', '2015-2017'),\n",
    "    ('2018-01-01', '2019-12-31', '2018-2019'),\n",
    "    ('2020-01-01', '2021-12-31', '2020-2021 (COVID)'),\n",
    "    ('2022-01-01', '2023-12-31', '2022-2023'),\n",
    "    ('2024-01-01', '2025-07-31', '2024-2025')\n",
    "]\n",
    "\n",
    "# Analyze each strategy by time period\n",
    "period_analysis = {}\n",
    "\n",
    "for strategy_name, results in backtest_results.items():\n",
    "    strategy_periods = []\n",
    "    \n",
    "    for start_date, end_date, period_name in analysis_periods:\n",
    "        period_result = analyze_period_performance(\n",
    "            results['returns'], start_date, end_date, period_name\n",
    "        )\n",
    "        if period_result:\n",
    "            strategy_periods.append(period_result)\n",
    "    \n",
    "    period_analysis[strategy_name] = pd.DataFrame(strategy_periods)\n",
    "\n",
    "# Display period analysis for optimized portfolio\n",
    "optimized_strategy = 'Optimized Portfolio'\n",
    "if optimized_strategy in period_analysis:\n",
    "    print(f\"PERIOD ANALYSIS - {optimized_strategy}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(period_analysis[optimized_strategy].round(2).to_string(index=False))\n",
    "\n",
    "# Compare strategies across periods\n",
    "print(f\"\\nSHARPE RATIO COMPARISON ACROSS PERIODS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sharpe_comparison = {}\n",
    "for strategy_name, period_df in period_analysis.items():\n",
    "    sharpe_comparison[strategy_name] = period_df.set_index('Period')['Sharpe Ratio']\n",
    "\n",
    "sharpe_df = pd.DataFrame(sharpe_comparison)\n",
    "print(sharpe_df.round(3))\n",
    "\n",
    "# Visualize period performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Time-Based Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Sharpe ratio by period\n",
    "ax1 = axes[0, 0]\n",
    "sharpe_df.plot(kind='bar', ax=ax1, alpha=0.8)\n",
    "ax1.set_title('Sharpe Ratio by Period')\n",
    "ax1.set_ylabel('Sharpe Ratio')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Return by period\n",
    "ax2 = axes[0, 1]\n",
    "return_comparison = {}\n",
    "for strategy_name, period_df in period_analysis.items():\n",
    "    return_comparison[strategy_name] = period_df.set_index('Period')['Total Return']\n",
    "\n",
    "return_df = pd.DataFrame(return_comparison)\n",
    "return_df.plot(kind='bar', ax=ax2, alpha=0.8)\n",
    "ax2.set_title('Total Return by Period (%)')\n",
    "ax2.set_ylabel('Total Return (%)')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Volatility by period\n",
    "ax3 = axes[1, 0]\n",
    "vol_comparison = {}\n",
    "for strategy_name, period_df in period_analysis.items():\n",
    "    vol_comparison[strategy_name] = period_df.set_index('Period')['Volatility']\n",
    "\n",
    "vol_df = pd.DataFrame(vol_comparison)\n",
    "vol_df.plot(kind='bar', ax=ax3, alpha=0.8)\n",
    "ax3.set_title('Volatility by Period (%)')\n",
    "ax3.set_ylabel('Volatility (%)')\n",
    "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Max drawdown by period\n",
    "ax4 = axes[1, 1]\n",
    "dd_comparison = {}\n",
    "for strategy_name, period_df in period_analysis.items():\n",
    "    dd_comparison[strategy_name] = period_df.set_index('Period')['Max Drawdown']\n",
    "\n",
    "dd_df = pd.DataFrame(dd_comparison)\n",
    "dd_df.plot(kind='bar', ax=ax4, alpha=0.8)\n",
    "ax4.set_title('Max Drawdown by Period (%)')\n",
    "ax4.set_ylabel('Max Drawdown (%)')\n",
    "ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Testing and Scenario Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress testing framework\n",
    "class StressTester:\n",
    "    \"\"\"\n",
    "    Portfolio stress testing and scenario analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns_data, weights):\n",
    "        self.returns = returns_data\n",
    "        self.weights = pd.Series(weights) if isinstance(weights, dict) else weights\n",
    "        self.portfolio_returns = (returns_data * self.weights).sum(axis=1)\n",
    "        \n",
    "    def tail_risk_analysis(self):\n",
    "        \"\"\"\n",
    "        Analyze tail risk scenarios\n",
    "        \"\"\"\n",
    "        # Identify worst performing days\n",
    "        worst_days = self.portfolio_returns.nsmallest(10)\n",
    "        best_days = self.portfolio_returns.nlargest(10)\n",
    "        \n",
    "        # Calculate tail statistics\n",
    "        var_95 = np.percentile(self.portfolio_returns, 5)\n",
    "        var_99 = np.percentile(self.portfolio_returns, 1)\n",
    "        var_999 = np.percentile(self.portfolio_returns, 0.1)\n",
    "        \n",
    "        cvar_95 = self.portfolio_returns[self.portfolio_returns <= var_95].mean()\n",
    "        cvar_99 = self.portfolio_returns[self.portfolio_returns <= var_99].mean()\n",
    "        \n",
    "        return {\n",
    "            'worst_days': worst_days,\n",
    "            'best_days': best_days,\n",
    "            'var_95': var_95,\n",
    "            'var_99': var_99,\n",
    "            'var_999': var_999,\n",
    "            'cvar_95': cvar_95,\n",
    "            'cvar_99': cvar_99\n",
    "        }\n",
    "    \n",
    "    def market_crash_scenarios(self):\n",
    "        \"\"\"\n",
    "        Analyze performance during market crashes\n",
    "        \"\"\"\n",
    "        # Define crash periods (approximate)\n",
    "        crash_periods = {\n",
    "            'COVID Crash': ('2020-02-20', '2020-03-23'),\n",
    "            'Dec 2018 Selloff': ('2018-10-01', '2018-12-24'),\n",
    "            'Early 2022 Correction': ('2022-01-01', '2022-03-15'),\n",
    "            'Aug 2015 Correction': ('2015-08-01', '2015-08-31')\n",
    "        }\n",
    "        \n",
    "        crash_performance = {}\n",
    "        \n",
    "        for crash_name, (start_date, end_date) in crash_periods.items():\n",
    "            try:\n",
    "                crash_returns = self.portfolio_returns[\n",
    "                    (self.portfolio_returns.index >= start_date) & \n",
    "                    (self.portfolio_returns.index <= end_date)\n",
    "                ]\n",
    "                \n",
    "                if len(crash_returns) > 0:\n",
    "                    total_return = (1 + crash_returns).prod() - 1\n",
    "                    max_dd = ((1 + crash_returns).cumprod() / \n",
    "                             (1 + crash_returns).cumprod().expanding().max() - 1).min()\n",
    "                    \n",
    "                    crash_performance[crash_name] = {\n",
    "                        'total_return': total_return * 100,\n",
    "                        'max_drawdown': max_dd * 100,\n",
    "                        'worst_day': crash_returns.min() * 100,\n",
    "                        'volatility': crash_returns.std() * np.sqrt(252) * 100\n",
    "                    }\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return crash_performance\n",
    "    \n",
    "    def monte_carlo_stress_test(self, n_simulations=10000, time_horizon=252):\n",
    "        \"\"\"\n",
    "        Monte Carlo stress testing\n",
    "        \"\"\"\n",
    "        # Calculate portfolio statistics\n",
    "        mean_return = self.portfolio_returns.mean()\n",
    "        volatility = self.portfolio_returns.std()\n",
    "        \n",
    "        # Generate random scenarios\n",
    "        np.random.seed(42)\n",
    "        simulated_returns = np.random.normal(mean_return, volatility, \n",
    "                                           (n_simulations, time_horizon))\n",
    "        \n",
    "        # Calculate final portfolio values\n",
    "        final_values = np.prod(1 + simulated_returns, axis=1)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        percentile_values = np.percentile(final_values, percentiles)\n",
    "        \n",
    "        return {\n",
    "            'percentiles': dict(zip(percentiles, percentile_values)),\n",
    "            'probability_of_loss': np.mean(final_values < 1) * 100,\n",
    "            'expected_value': np.mean(final_values),\n",
    "            'worst_case_1pct': np.percentile(final_values, 1)\n",
    "        }\n",
    "\n",
    "# Perform stress testing on optimized portfolio\n",
    "stress_tester = StressTester(returns, recommended_weights)\n",
    "\n",
    "print(\"STRESS TESTING ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tail risk analysis\n",
    "tail_risk = stress_tester.tail_risk_analysis()\n",
    "\n",
    "print(f\"\\nTAIL RISK ANALYSIS:\")\n",
    "print(f\"-\" * 30)\n",
    "print(f\"VaR 95%: {tail_risk['var_95']*100:.2f}%\")\n",
    "print(f\"VaR 99%: {tail_risk['var_99']*100:.2f}%\")\n",
    "print(f\"VaR 99.9%: {tail_risk['var_999']*100:.2f}%\")\n",
    "print(f\"CVaR 95%: {tail_risk['cvar_95']*100:.2f}%\")\n",
    "print(f\"CVaR 99%: {tail_risk['cvar_99']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nWorst 5 Days:\")\n",
    "for date, return_val in tail_risk['worst_days'].head().items():\n",
    "    print(f\"  {date.strftime('%Y-%m-%d')}: {return_val*100:.2f}%\")\n",
    "\n",
    "# Market crash analysis\n",
    "crash_performance = stress_tester.market_crash_scenarios()\n",
    "\n",
    "print(f\"\\nMARKET CRASH PERFORMANCE:\")\n",
    "print(f\"-\" * 30)\n",
    "for crash_name, performance in crash_performance.items():\n",
    "    print(f\"\\n{crash_name}:\")\n",
    "    print(f\"  Total Return: {performance['total_return']:.2f}%\")\n",
    "    print(f\"  Max Drawdown: {performance['max_drawdown']:.2f}%\")\n",
    "    print(f\"  Worst Day: {performance['worst_day']:.2f}%\")\n",
    "    print(f\"  Volatility: {performance['volatility']:.2f}%\")\n",
    "\n",
    "# Monte Carlo stress test\n",
    "mc_stress = stress_tester.monte_carlo_stress_test()\n",
    "\n",
    "print(f\"\\nMONTE CARLO STRESS TEST (1-Year Horizon):\")\n",
    "print(f\"-\" * 30)\n",
    "print(f\"Expected Portfolio Value: {mc_stress['expected_value']:.3f}\")\n",
    "print(f\"Probability of Loss: {mc_stress['probability_of_loss']:.2f}%\")\n",
    "print(f\"Worst Case (1%): {mc_stress['worst_case_1pct']:.3f}\")\n",
    "\n",
    "print(f\"\\nPercentile Distribution:\")\n",
    "for percentile, value in mc_stress['percentiles'].items():\n",
    "    print(f\"  {percentile}th percentile: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stress testing results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Stress Testing and Risk Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Return distribution with VaR levels\n",
    "ax1 = axes[0, 0]\n",
    "portfolio_returns = stress_tester.portfolio_returns\n",
    "ax1.hist(portfolio_returns*100, bins=50, alpha=0.7, density=True, color='skyblue')\n",
    "ax1.axvline(tail_risk['var_95']*100, color='orange', linestyle='--', linewidth=2, label='VaR 95%')\n",
    "ax1.axvline(tail_risk['var_99']*100, color='red', linestyle='--', linewidth=2, label='VaR 99%')\n",
    "ax1.axvline(tail_risk['cvar_95']*100, color='darkred', linestyle=':', linewidth=2, label='CVaR 95%')\n",
    "ax1.set_xlabel('Daily Returns (%)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Return Distribution with Risk Measures')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Crash performance comparison\n",
    "ax2 = axes[0, 1]\n",
    "if crash_performance:\n",
    "    crash_names = list(crash_performance.keys())\n",
    "    crash_returns = [perf['total_return'] for perf in crash_performance.values()]\n",
    "    crash_drawdowns = [perf['max_drawdown'] for perf in crash_performance.values()]\n",
    "    \n",
    "    x = np.arange(len(crash_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax2.bar(x - width/2, crash_returns, width, label='Total Return', alpha=0.8)\n",
    "    ax2.bar(x + width/2, crash_drawdowns, width, label='Max Drawdown', alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Market Crash Period')\n",
    "    ax2.set_ylabel('Return (%)')\n",
    "    ax2.set_title('Performance During Market Crashes')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(crash_names, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Monte Carlo simulation results\n",
    "ax3 = axes[1, 0]\n",
    "percentiles = list(mc_stress['percentiles'].keys())\n",
    "values = list(mc_stress['percentiles'].values())\n",
    "\n",
    "ax3.plot(percentiles, values, marker='o', linewidth=2, markersize=6)\n",
    "ax3.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Break-even')\n",
    "ax3.fill_between(percentiles, values, 1, where=np.array(values) < 1, \n",
    "                alpha=0.3, color='red', label='Loss Region')\n",
    "ax3.set_xlabel('Percentile')\n",
    "ax3.set_ylabel('Portfolio Value')\n",
    "ax3.set_title('Monte Carlo Simulation Results (1-Year)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Rolling maximum drawdown\n",
    "ax4 = axes[1, 1]\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "rolling_max = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - rolling_max) / rolling_max\n",
    "rolling_max_dd = drawdown.rolling(252).min()  # 1-year rolling max drawdown\n",
    "\n",
    "ax4.fill_between(rolling_max_dd.index, rolling_max_dd*100, 0, alpha=0.7, color='red')\n",
    "ax4.set_title('Rolling Maximum Drawdown (1-Year)')\n",
    "ax4.set_ylabel('Max Drawdown (%)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Risk budget analysis\n",
    "print(f\"\\nRISK BUDGET ANALYSIS:\")\n",
    "print(f\"-\" * 30)\n",
    "\n",
    "# Calculate individual asset contributions to portfolio risk\n",
    "weights_series = pd.Series(recommended_weights)\n",
    "cov_matrix = returns.cov() * 252\n",
    "portfolio_variance = np.dot(weights_series.T, np.dot(cov_matrix, weights_series))\n",
    "portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "\n",
    "marginal_contrib = np.dot(cov_matrix, weights_series) / portfolio_volatility\n",
    "component_contrib = weights_series * marginal_contrib\n",
    "risk_contrib_pct = component_contrib / component_contrib.sum() * 100\n",
    "\n",
    "print(f\"Portfolio Volatility: {portfolio_volatility*100:.2f}%\")\n",
    "print(f\"\\nRisk Contribution by Asset:\")\n",
    "for asset in assets:\n",
    "    if asset in risk_contrib_pct.index:\n",
    "        weight = weights_series[asset] * 100\n",
    "        risk_contrib = risk_contrib_pct[asset]\n",
    "        print(f\"  {asset}: {weight:.1f}% weight, {risk_contrib:.1f}% risk contribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Backtesting Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive backtesting summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE BACKTESTING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best performing strategy\n",
    "best_strategy_name = performance_df.iloc[0]['Strategy']\n",
    "best_metrics = backtest_results[best_strategy_name]['metrics']\n",
    "\n",
    "print(f\"\\n1. BEST PERFORMING STRATEGY: {best_strategy_name}\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"• Total Return: {best_metrics['Total Return']*100:.2f}%\")\n",
    "print(f\"• Annualized Return: {best_metrics['Annualized Return']*100:.2f}%\")\n",
    "print(f\"• Volatility: {best_metrics['Annualized Volatility']*100:.2f}%\")\n",
    "print(f\"• Sharpe Ratio: {best_metrics['Sharpe Ratio']:.3f}\")\n",
    "print(f\"• Maximum Drawdown: {best_metrics['Max Drawdown']*100:.2f}%\")\n",
    "print(f\"• Information Ratio: {best_metrics['Information Ratio']:.3f}\")\n",
    "print(f\"• Alpha vs SPY: {best_metrics['Alpha']*100:.2f}%\")\n",
    "\n",
    "# Strategy comparison insights\n",
    "print(f\"\\n2. STRATEGY COMPARISON INSIGHTS:\")\n",
    "print(f\"-\" * 50)\n",
    "\n",
    "# Compare optimized vs equal weight\n",
    "if 'Optimized Portfolio' in backtest_results and 'Equal Weight' in backtest_results:\n",
    "    opt_sharpe = backtest_results['Optimized Portfolio']['metrics']['Sharpe Ratio']\n",
    "    eq_sharpe = backtest_results['Equal Weight']['metrics']['Sharpe Ratio']\n",
    "    sharpe_improvement = ((opt_sharpe - eq_sharpe) / eq_sharpe) * 100\n",
    "    \n",
    "    opt_return = backtest_results['Optimized Portfolio']['metrics']['Annualized Return']\n",
    "    eq_return = backtest_results['Equal Weight']['metrics']['Annualized Return']\n",
    "    return_improvement = (opt_return - eq_return) * 100\n",
    "    \n",
    "    print(f\"• Optimized vs Equal Weight:\")\n",
    "    print(f\"  - Sharpe Ratio improvement: {sharpe_improvement:+.1f}%\")\n",
    "    print(f\"  - Return improvement: {return_improvement:+.2f}% annually\")\n",
    "\n",
    "# Compare with traditional 60/40\n",
    "if 'Optimized Portfolio' in backtest_results and '60/40 Traditional' in backtest_results:\n",
    "    opt_sharpe = backtest_results['Optimized Portfolio']['metrics']['Sharpe Ratio']\n",
    "    trad_sharpe = backtest_results['60/40 Traditional']['metrics']['Sharpe Ratio']\n",
    "    \n",
    "    opt_vol = backtest_results['Optimized Portfolio']['metrics']['Annualized Volatility']\n",
    "    trad_vol = backtest_results['60/40 Traditional']['metrics']['Annualized Volatility']\n",
    "    \n",
    "    print(f\"• Optimized vs 60/40 Traditional:\")\n",
    "    print(f\"  - Sharpe Ratio: {opt_sharpe:.3f} vs {trad_sharpe:.3f}\")\n",
    "    print(f\"  - Volatility: {opt_vol*100:.2f}% vs {trad_vol*100:.2f}%\")\n",
    "\n",
    "# Risk analysis summary\n",
    "print(f\"\\n3. RISK ANALYSIS SUMMARY:\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"• Daily VaR (95%): {tail_risk['var_95']*100:.2f}%\")\n",
    "print(f\"• Daily VaR (99%): {tail_risk['var_99']*100:.2f}%\")\n",
    "print(f\"• Expected Shortfall (95%): {tail_risk['cvar_95']*100:.2f}%\")\n",
    "print(f\"• Probability of annual loss: {mc_stress['probability_of_loss']:.1f}%\")\n",
    "print(f\"• Worst-case scenario (1%): {(mc_stress['worst_case_1pct']-1)*100:.1f}% annual return\")\n",
    "\n",
    "# Market crash resilience\n",
    "if crash_performance:\n",
    "    avg_crash_return = np.mean([perf['total_return'] for perf in crash_performance.values()])\n",
    "    avg_crash_dd = np.mean([perf['max_drawdown'] for perf in crash_performance.values()])\n",
    "    \n",
    "    print(f\"\\n4. MARKET CRASH RESILIENCE:\")\n",
    "    print(f\"-\" * 50)\n",
    "    print(f\"• Average return during crashes: {avg_crash_return:.2f}%\")\n",
    "    print(f\"• Average max drawdown during crashes: {avg_crash_dd:.2f}%\")\n",
    "    print(f\"• Number of crash periods analyzed: {len(crash_performance)}\")\n",
    "\n",
    "# Time period performance\n",
    "print(f\"\\n5. TIME PERIOD PERFORMANCE:\")\n",
    "print(f\"-\" * 50)\n",
    "if optimized_strategy in period_analysis:\n",
    "    period_df = period_analysis[optimized_strategy]\n",
    "    best_period = period_df.loc[period_df['Sharpe Ratio'].idxmax()]\n",
    "    worst_period = period_df.loc[period_df['Sharpe Ratio'].idxmin()]\n",
    "    \n",
    "    print(f\"• Best performing period: {best_period['Period']}\")\n",
    "    print(f\"  - Sharpe Ratio: {best_period['Sharpe Ratio']:.3f}\")\n",
    "    print(f\"  - Total Return: {best_period['Total Return']:.2f}%\")\n",
    "    \n",
    "    print(f\"• Worst performing period: {worst_period['Period']}\")\n",
    "    print(f\"  - Sharpe Ratio: {worst_period['Sharpe Ratio']:.3f}\")\n",
    "    print(f\"  - Total Return: {worst_period['Total Return']:.2f}%\")\n",
    "\n",
    "# Implementation insights\n",
    "print(f\"\\n6. IMPLEMENTATION INSIGHTS:\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"• Rebalancing frequency tested: Monthly\")\n",
    "print(f\"• Transaction costs not included (would reduce returns)\")\n",
    "print(f\"• Tax implications not considered\")\n",
    "print(f\"• Model assumes perfect execution\")\n",
    "\n",
    "# Key findings\n",
    "print(f\"\\n7. KEY FINDINGS:\")\n",
    "print(f\"-\" * 50)\n",
    "\n",
    "# Determine if optimization worked\n",
    "optimization_success = False\n",
    "if 'Optimized Portfolio' in backtest_results:\n",
    "    opt_sharpe = backtest_results['Optimized Portfolio']['metrics']['Sharpe Ratio']\n",
    "    \n",
    "    # Compare with other strategies\n",
    "    other_sharpes = [results['metrics']['Sharpe Ratio'] \n",
    "                    for name, results in backtest_results.items() \n",
    "                    if name != 'Optimized Portfolio']\n",
    "    \n",
    "    if opt_sharpe > max(other_sharpes):\n",
    "        optimization_success = True\n",
    "\n",
    "if optimization_success:\n",
    "    print(f\"✓ Portfolio optimization was successful\")\n",
    "    print(f\"✓ Optimized portfolio outperformed benchmarks\")\n",
    "    print(f\"✓ Risk-adjusted returns were maximized\")\nelse:\n",
    "    print(f\"⚠ Portfolio optimization showed mixed results\")\n",
    "    print(f\"⚠ Consider alternative optimization approaches\")\n",
    "\n",
    "# Check if forecasting helped\n",
    "if portfolio_rec and 'TSLA' in recommended_weights:\n",
    "    tsla_weight = recommended_weights['TSLA']\n",
    "    if tsla_weight > 0.3:  # Significant TSLA allocation\n",
    "        print(f\"✓ Forecasting models influenced portfolio allocation\")\n",
    "        print(f\"✓ TSLA allocation: {tsla_weight*100:.1f}% based on forecasts\")\n",
    "    else:\n",
    "        print(f\"⚠ Conservative TSLA allocation despite forecasts\")\n",
    "\n",
    "# Final recommendations\n",
    "print(f\"\\n8. FINAL RECOMMENDATIONS:\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"• Implement {best_strategy_name} for optimal risk-adjusted returns\")\n",
    "print(f\"• Rebalance monthly or when weights deviate >5%\")\n",
    "print(f\"• Monitor portfolio during high volatility periods\")\n",
    "print(f\"• Consider transaction costs in implementation\")\n",
    "print(f\"• Review and update forecasts quarterly\")\n",
    "print(f\"• Set stop-loss rules for individual positions if desired\")\n",
    "print(f\"• Maintain emergency cash reserves outside this portfolio\")\n",
    "\n",
    "print(f\"\\n9. LIMITATIONS AND CAVEATS:\")\n",
    "print(f\"-\" * 50)\n",
    "print(f\"• Backtesting uses historical data (past ≠ future)\")\n",
    "print(f\"• Transaction costs and slippage not included\")\n",
    "print(f\"• Tax implications vary by investor\")\n",
    "print(f\"• Model assumes rational markets and perfect execution\")\n",
    "print(f\"• Forecasting accuracy may degrade over time\")\n",
    "print(f\"• Correlation patterns may change in future\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"BACKTESTING ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save backtesting results\n",
    "backtesting_summary = {\n",
    "    'best_strategy': best_strategy_name,\n",
    "    'performance_comparison': performance_df.to_dict('records'),\n",
    "    'stress_test_results': {\n",
    "        'tail_risk': {k: v for k, v in tail_risk.items() if"
   ]
}
]
}